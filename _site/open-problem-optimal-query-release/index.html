<!DOCTYPE html>
<html>
  <head>
    <title>Differential Privacy - Open Problem - Optimal Query Release for Pure Differential Privacy</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@DiffPriv" />
    <meta name="twitter:image" content="https://differentialprivacy.org/images/logodp.png" />
    <meta name="twitter:image:alt" content="DP.org logo" />

    
    <meta name="description" content="Releasing large sets of statistical queries is a centerpiece of the theory of differential privacy.  Here, we are given a dataset \(x = (x_1,\dots,x_n) \in [T]^n\), and a set of statistical queries \(f_1,\dots,f_k\), where each query is defined by some bounded function \(f_j : [T] \to [-1,1]\), and (abusing notation) is defined as
\[
f_j(x) = \frac{1}{n} \sum_{i=1}^{n} f_j(x_i).
\]
We use \(f(x) = (f_1(x),\dots,f_k(x))\) to denote the vector consisting of the true answers to all these queries.
Our goal is to design an \((\varepsilon, \delta)\)-differentially private algorithm \(M\) that takes a dataset \(x\in [T]^n\) and outputs a random vector \(M(x)\in \mathbb{R}^k\) such that \(\| M(x) - f(x) \|\) is small in expectation for some norm \(\|\cdot\|\). Usually algorithms for this problem also give high probability bounds on the error, but we focus on expected error for simplicity.
" />
    <meta property="og:description" content="Releasing large sets of statistical queries is a centerpiece of the theory of differential privacy.  Here, we are given a dataset \(x = (x_1,\dots,x_n) \in [T]^n\), and a set of statistical queries \(f_1,\dots,f_k\), where each query is defined by some bounded function \(f_j : [T] \to [-1,1]\), and (abusing notation) is defined as
\[
f_j(x) = \frac{1}{n} \sum_{i=1}^{n} f_j(x_i).
\]
We use \(f(x) = (f_1(x),\dots,f_k(x))\) to denote the vector consisting of the true answers to all these queries.
Our goal is to design an \((\varepsilon, \delta)\)-differentially private algorithm \(M\) that takes a dataset \(x\in [T]^n\) and outputs a random vector \(M(x)\in \mathbb{R}^k\) such that \(\| M(x) - f(x) \|\) is small in expectation for some norm \(\|\cdot\|\). Usually algorithms for this problem also give high probability bounds on the error, but we focus on expected error for simplicity.
" />
    <meta name="twitter:description" content="Releasing large sets of statistical queries is a centerpiece of the theory of differential privacy.  Here, we are given a dataset \(x = (x_1,\dots,x_n) \in [T]^n\), and a set of statistical queries \(f_1,\dots,f_k\), where each query is defined by some bounded function \(f_j : [T] \to [-1,1]\), and (abusing notation) is defined as
\[
f_j(x) = \frac{1}{n} \sum_{i=1}^{n} f_j(x_i).
\]
We use \(f(x) = (f_1(x),\dots,f_k(x))\) to denote the vector consisting of the true answers to all these queries.
Our goal is to design an \((\varepsilon, \delta)\)-differentially private algorithm \(M\) that takes a dataset \(x\in [T]^n\) and outputs a random vector \(M(x)\in \mathbb{R}^k\) such that \(\| M(x) - f(x) \|\) is small in expectation for some norm \(\|\cdot\|\). Usually algorithms for this problem also give high probability bounds on the error, but we focus on expected error for simplicity.
"/>
    
    <meta name="author" content="Differential Privacy" />

    
    <meta property="og:title" content="Open Problem - Optimal Query Release for Pure Differential Privacy" />
    <meta property="twitter:title" content="Open Problem - Optimal Query Release for Pure Differential Privacy" />
    


    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Differential Privacy - Website for the differential privacy research community" href="/feed.xml" />
	<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;700&display=swap" rel="stylesheet">

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
    <link rel="icon" type="image/png" sizes="96x96" href="/favicon-96x96.png">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <!-- no image for now <a href="/" class="site-avatar"><img src="favicon-96x96.png" /></a> -->

          <div class="site-info">
            <h1 class="site-name"><a href="/"><b><font color="#3d85c6">Differential</font><font color="#b45f06">Privacy</font><font color="#cccccc">.org</font></b></a></h1>
            <!-- <p class="site-description">Website for the differential privacy research community</p> -->
          </div>

          <nav>
            <a href="/">Home</a>
            <a href="/about">About</a>
			<a href="/categories">Posts</a>
			<a href="/resources">Resources</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Open Problem - Optimal Query Release for Pure Differential Privacy</h1>

  <div class="entry">
    <p>Releasing large sets of statistical queries is a centerpiece of the theory of differential privacy.  Here, we are given a <em>dataset</em> \(x = (x_1,\dots,x_n) \in [T]^n\), and a set of <em>statistical queries</em> \(f_1,\dots,f_k\), where each query is defined by some bounded function \(f_j : [T] \to [-1,1]\), and (abusing notation) is defined as
\[
f_j(x) = \frac{1}{n} \sum_{i=1}^{n} f_j(x_i).
\]
We use \(f(x) = (f_1(x),\dots,f_k(x))\) to denote the vector consisting of the true answers to all these queries.
Our goal is to design an \((\varepsilon, \delta)\)-differentially private algorithm \(M\) that takes a dataset \(x\in [T]^n\) and outputs a random vector \(M(x)\in \mathbb{R}^k\) such that \(\| M(x) - f(x) \|\) is small in expectation for some norm \(\|\cdot\|\). Usually algorithms for this problem also give high probability bounds on the error, but we focus on expected error for simplicity.</p>

<p>This problem has been studied for both <em>pure differential privacy</em> (\(\delta = 0\)) and <em>appproximate differential privacy</em> (\(\delta &gt; 0\)), and for both \(\ell_\infty\)-error
\[
\mathbb{E}( \| M(x) - f(x)\|_{\infty} ) \leq \alpha,
\]
and \(\ell_2\)-error
\[
\mathbb{E}( \| M(x) - f(x)\|_{2} ) \leq \alpha k^{1/2},
\]
giving four variants of the problem.  By now we know tight worst-case upper and lower bounds for two of these variants, and nearly tight bounds (up to logarithmic factors) for a third. The tightest known upper bounds are given in the following table.</p>

<table>
  <tbody>
    <tr>
      <td>Â </td>
      <td>Pure DP</td>
      <td>Approx DP</td>
    </tr>
    <tr>
      <td>\( \ell_2 \)<br />error</td>
      <td>\( \alpha \lesssim \left(\frac{\log^2 k ~\cdot~ \log^{3/2}T}{\varepsilon n} \right)^{1/2} \) <br /> [<a href="https://arxiv.org/abs/1212.0297">NTZ13</a>]</td>
      <td>\( \alpha \lesssim \left(\frac{\log^{1/2} T}{\varepsilon n} \right)^{1/2} \) <br /> [<a href="https://guyrothblum.files.wordpress.com/2014/11/drv10.pdf">DRV10</a>]</td>
    </tr>
    <tr>
      <td>\( \ell_\infty \)<br />error</td>
      <td>\( \alpha \lesssim \left(\frac{\log k ~\cdot~ \log T}{\varepsilon n} \right)^{1/3} \)  <br /> [<a href="https://arxiv.org/abs/1109.2229">BLR13</a>]</td>
      <td>\( \alpha \lesssim \left(\frac{\log k ~\cdot~ \log^{1/2} T}{\varepsilon n} \right)^{1/2} \) <br /> [<a href="https://guyrothblum.files.wordpress.com/2014/11/hr10.pdf">HR10</a>, <a href="https://arxiv.org/abs/1107.3731">GRU12</a>]</td>
    </tr>
  </tbody>
</table>

<p>The bounds for approximate DP are known to be tight [<a href="https://arxiv.org/abs/1311.3158">BUV14</a>].  Our two open problems both involve improving the best known upper bounds for pure differential privacy.</p>

<blockquote>
  <p><b>Open Problem 1:</b> What is the best possible \(\ell_\infty\)-error for answering a worst-case set of \(k\) statistical queries over a domain of size \(T\) subject to \((\varepsilon,0)\)-differential privacy?</p>
</blockquote>

<p>We conjecture that the known upper bound in the table can be improved to
\[
\alpha = \left(\frac{\log k \cdot \log T}{\varepsilon n} \right)^{1/2},
\]
which is known to be the best possible [<a href="https://dataspace.princeton.edu/handle/88435/dsp01vq27zn422">Har11</a>, Theorem 4.5.1].</p>

<blockquote>
  <p><b>Open Problem 2:</b> What is the best possible \(\ell_2\)-error for answering a worst-case set of \(k\) statistical queries over a domain of size \(T\) subject to \((\varepsilon,0)\)-differential privacy?</p>
</blockquote>

<p>We conjecture that the upper bound can be improved to
\[
\alpha = \left(\frac{\log T}{\varepsilon n} \right)^{1/2}.
\]
The construction used in [<a href="https://dataspace.princeton.edu/handle/88435/dsp01vq27zn422">Har11</a>, Theorem 4.5.1] can be analyzed to show this bound would be tight. Note, in particular, that this conjecture implies that the tight upper bound has no dependence on the number of queries, similarly to the case of \(\ell_2\) error and approximate DP.</p>

  </div>

  <div class="date">
      Posted by <a href="http://www.cs.toronto.edu/~anikolov/">Sasho Nikolov</a> and <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a> on July  7, 2021.
  </div>
  <div class="post-categories">
    
	Categories: 
    
    <a href="/categories/#Open Problems">Open Problems</a>
    
    
  </div>
  
  <br/>

  
  <a href="/bibtex/#open-problem-optimal-query-release">[cite this]</a> &nbsp;
  
  <!-- 
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'differentialprivacy';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
 -->
  
  <span class="disqus-comment-count" data-disqus-url="http://localhost:4000/open-problem-optimal-query-release/"> <!-- Comment count will be inserted here --> </span>


  <br/>&nbsp;<br/>
 <div class="comments-block">
     <center><button id="show-comments" onclick="disqus();return false;">SHOW COMMENTS</button></center>
 </div>
 <noscript>Comments cannot be shown due to javascript being disabled in your browser.</noscript>
 

 <div id="disqus_thread"></div>
 
 <script id="dsq-count-scr" src="//differentialprivacy.disqus.com/count.js" async></script>
 
 <script>
 var disqus_loaded = false;
 var disqus_shortname = 'differentialprivacy'; //Add your shortname here

 function disqus() {

     if (!disqus_loaded)  {
         disqus_loaded = true;

         var e = document.createElement("script");
         e.type = "text/javascript";
         e.async = true;
         e.src = "//" + disqus_shortname + ".disqus.com/embed.js";
         (document.getElementsByTagName("head")[0] ||
         document.getElementsByTagName("body")[0])
         .appendChild(e);

         //Hide the button after opening
         document.getElementById("show-comments").style.display = "none";
     }
 }

 //Opens comments when linked to directly
 var hash = window.location.hash.substr(1);
 if (hash.length > 8) {
     if (hash.substring(0, 8) == "comment-") {
         disqus();
     }
 }

 //Remove this if you don't want to load comments for search engines
 if(/bot|google|baidu|bing|msn|duckduckgo|slurp|yandex/i.test(navigator.userAgent)) {
    disqus();
 }
 </script>
  
  
  <br/>&nbsp;<br/>

  <div>Subscribe to updates from DifferentialPrivacy.org by <a href="https://feedburner.google.com/fb/a/mailverify?uri=DifferentialPrivacy">Email</a>, on <a href="https://twitter.com/DiffPriv">Twitter</a>, or via <a href="/feed.xml">RSS</a>.</div>
  
  <br/>&nbsp;<br/>
</article>

    </div>

    <!--
    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          



<a href="https://github.com/differentialprivacy/differentialprivacy"><i class="svg-icon github"></i></a>




<a href="https://www.twitter.com/DiffPriv"><i class="svg-icon twitter"></i></a>



        </footer>
      </div>
    </div>
    -->

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-11154678-4', 'auto');
		ga('send', 'pageview', {
		  'page': '/open-problem-optimal-query-release/',
		  'title': 'Open Problem - Optimal Query Release for Pure Differential Privacy'
		});
	</script>
	<!-- End Google Analytics -->


    
    <!-- 
    <script>
     
        var disqus_shortname = "differentialprivacy";
        var disqus_config = function () {
            this.page.url = '/open-problem-optimal-query-release/';
            this.page.identifier = '/open-problem-optimal-query-release';
        };
        var is_disqus_loaded = false;
        function loadDisqus() {
          if (!is_disqus_loaded){
            is_disqus_loaded = true;
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
          }
            
        };
    </script>
     -->
  </body>
</html>
